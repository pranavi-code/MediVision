<h1>ğŸ©º MediVision â€” Multimodal AI for Realâ€‘Time Chest Xâ€‘ray Diagnosis</h1>
<p>FastAPI + React app that combines a multimodal LLM with domain tools (classification, segmentation, VQA, grounding, report generation) to assist clinical CXR interpretation in real time.</p>
<p align="center"> <a href="https://arxiv.org/abs/2502.02673" target="_blank"><img src="https://img.shields.io/badge/arXiv-ICML 2025-FF6B6B?style=for-the-badge&logo=arxiv&logoColor=white" alt="arXiv"></a> <a href="https://github.com/bowang-lab/MedRAX"><img src="https://img.shields.io/badge/GitHub-Code-4A90E2?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"></a> <a href="https://huggingface.co/datasets/wanglab/chest-agent-bench"><img src="https://img.shields.io/badge/HuggingFace-Dataset-FFBF00?style=for-the-badge&logo=huggingface&logoColor=white" alt="HuggingFace Dataset"></a> </p>

![](assets/demo_fast.gif?autoplay=1)

<br>

## ğŸ“ Abstract
MediVision is an intelligent, agentic system designed to assist clinicians or radiologists in interpreting chest Xâ€‘rays (CXRs) through natural language queries and multimodal reasoning. Built on a privacyâ€‘conscious architecture, it integrates a powerful multimodal LLM (configurable: GPTâ€‘4o, LLaVAâ€‘Med, or local LLMs via Ollama) with a suite of specialized tools such as MedSAM, CheXagent, DenseNetâ€‘121, SwinV2, Mairaâ€‘2, and optionally RoentGen to perform segmentation, classification, visual question answering, grounding, and report generation.

Using a ReActâ€‘style agent workflow via LangChain/LangGraph, MediVision dynamically selects and orchestrates tools to handle complex, multiâ€‘step clinical queries. It supports memoryâ€‘aware interactions and optional persistence with MongoDB. The system can be evaluated with ChestAgentBenchâ€”a benchmark of 2,500 curated queries across 7 categoriesâ€”demonstrating strong performance in diagnosis, localization, and visual explanation tasks.

MediVision improves diagnostic efficiency, supports medical education, and enables transparent, realâ€‘time AI assistance in clinical workflows, making it a valuable tool in modern healthcare settings.

<br/>

## ğŸ”‘ Key Features
- ğŸ‘¨â€âš•ï¸ Roleâ€‘aware assistant: doctor, patient, and general/teaching personas are injected serverâ€‘side.
- ğŸ“‹ Structured output: concise â€œFindingsâ€ (top 3 â‰¥ 0.15 probability) and a singleâ€‘line â€œImpressionâ€.
- ğŸ§  Multimodal reasoning: GPTâ€‘4o/LLaVAâ€‘Med or local LLMs + domain tools for segmentation, classification, grounding, VQA, and reporting.
- ğŸ”„ Agentic execution: ReActâ€‘style tool selection/orchestration with streaming responses; tool chatter hidden.
- ğŸ‘‹ Greeting shortâ€‘circuit: simple greetings answered briefly without running tools.
- ğŸ–¼ï¸ DICOM/image workflows: upload, preview, and stable rendering (persisted display paths) in chat and history.
- ğŸ§µ Thread persistence: restore prior conversations with both user and assistant turns; no empty placeholders.
- ğŸ› ï¸ Admin dashboard: create cases, assign doctors/lab techs, manage users.
- âœ‰ï¸ Email notifications (EmailJS): separate doctor (credentials) and patient (case access) templates.
  - Doctors: credentials emailed immediately at creation (username=email; no insecure resend).
  - Patients: case access email with two login paths (Case ID + DOB, or Email + DOB).
- ğŸ”’ Privacyâ€‘minded: JWT auth, CORS, optional MongoDB persistence; designed to run behind TLS and RBAC.

<br/>

## ğŸ§± Architecture & Workflow
1. Requests enter FastAPI (`/api/*`) with JWT auth; role is derived from the token (doctor/patient/general).
2. The server injects the persona and enforces global output rules (no tool names, Findings/Impression format, conservative â€œnormalâ€ threshold).
3. The agent plans and invokes tools as needed (DICOM processing â†’ classification â†’ segmentation/grounding â†’ reporting) while streaming tokens to the client.
4. The server persists user and assistant turns (including image `display_path`) and strips persona prefixes from history for clean display.
5. The React app renders conversation and images, manages threads, and exposes admin flows; EmailJS sends notifications on create/resend events.

Notes:
- Greetings/noâ€‘image small talk bypasses tool calls for speed and UX.
- Tool names/outputs are never surfaced; replies synthesize findings in plain language.

<br/>

## ğŸ› ï¸ Tech Stack
**Frontend**
- React 18, Vite, TypeScript, Tailwind, shadcn/ui, React Router, TanStack Query

**Backend**
- FastAPI, Uvicorn, Pydantic, CORS, pythonâ€‘multipart
- LangChain / LangGraph for agent flow and memory

**Database (optional)**
- MongoDB (Motor/PyMongo) for cases, threads, and user management

**Agent, Tools, and Models**
- **Multimodal LLM**: GPTâ€‘4o or LLaVAâ€‘Med; local LLMs via Ollama (e.g., Qwen2.5, Mistral)
- **Visual QA**: Utilizes CheXagent and LLaVA-Med for complex visual understanding and medical reasoning
- **Segmentation**: Employs MedSAM and PSPNet model trained on ChestX-Det for precise anatomical structure identification
- **Grounding**: Uses Maira-2 for localizing specific findings in medical images
- **Report Generation**: Implements SwinV2 Transformer trained on CheXpert Plus for detailed medical reporting
- **Disease Classification**: Leverages DenseNet-121 from TorchXRayVision for detecting 18 pathology classes
- **X-ray Generation**: Utilizes RoentGen for synthetic CXR generation
- **Utilities**: Includes DICOM processing, visualization tools, and custom plotting capabilities
<br><br>

**Evaluation**
- ChestAgentBench: 2,500 expert queries across 7 diagnostic categories

<br/>

## ğŸ‘¥ Target Users
- ğŸ©º Doctors / Radiologists â€” accelerate interpretation with structured findings and concise impressions.
- ğŸ¥ Clinicians (ER, Pulmonology, ICU) â€” receive realâ€‘time support on likely findings and next steps.
- ğŸ“ Students / Trainees â€” learn diagnostic reasoning via a general/teaching persona with explanations.
- ğŸ› ï¸ Admins / IT â€” manage RBAC, cases, and deployment policies.
- ğŸ”¬ Researchers â€” study tool orchestration, agent behaviors, and benchmark performance.

<br/>

## â“ Why Agentic Workflows
- ğŸ¥ Handles complex, multiâ€‘step clinical tasks via planning and tool chaining.
- ğŸ”§ Combines multiple tools automatically (classification, segmentation, grounding, reporting).
- ğŸ’¯ Improves accuracy and flexibility by adapting to the specific question and context.
- ğŸ§  Mimics clinical reasoning: â€œWhatâ€™s the finding? Where is it? Has it changed?â€
- ğŸ” Enables comparisons over time (e.g., two CXRs) and subtle change detection.

<br/>

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+ and npm
- Optional CUDA/GPU for tool performance

### 1) Backend setup (FastAPI)
```powershell
# from repo root
python -m venv .venv ; .\.venv\Scripts\Activate.ps1
pip install -e .

# optional environment
$env:JWT_SECRET = "change-me"
# Optional DB for persistence
# $env:MONGODB_URI = "mongodb://localhost:27017/medivision"
# Defer heavy model init
$env:LAZY_INIT = "true"

# run API on 8585
python -m uvicorn api:app --reload --port 8585
```

Common backend env vars:
- JWT_SECRET â€” HMAC secret for JWT auth (required for protected admin routes)
- MONGODB_URI â€” optional, enables Mongo persistence for cases/threads
- LAZY_INIT=true â€” defer agent/tool initialization until first request
- FORCE_INIT=true with LAZY_INIT â€” background init after startup
- OLLAMA_BASE_URL â€” set if using a local LLM through Ollama
- CUDA_AVAILABLE=true â€” hint to prefer GPU

### 2) Frontend setup (Vite React)
Create `frontend/.env` (or `.env.local`) with your API and EmailJS settings:
```
VITE_API_URL=http://localhost:8585

# EmailJS
VITE_EMAILJS_SERVICE_ID=service_xxx
VITE_EMAILJS_PUBLIC_KEY=public_xxx
# Optional fallback template
VITE_EMAILJS_TEMPLATE_ID=template_fallback
# Specific templates (recommended)
VITE_EMAILJS_TEMPLATE_DOCTOR_ID=template_doctor_xxx
VITE_EMAILJS_TEMPLATE_PATIENT_ID=template_patient_xxx
```

Then install and run:
```powershell
cd frontend
npm install
npm run dev
```

The app expects the API at `VITE_API_URL` (defaults to `http://localhost:8585`).

<br/>

## âœ‰ï¸ Email Setup (EmailJS)
We use two templates, one for doctors and one for patients. In EmailJS:
- Create a service (SMTP or Gmail) and note its Service ID.
- Create two templates with Subject = `{{subject}}`.
- Doctor variables: `subject, greeting, body, username, password, specialty, login_url`.
- Patient variables: `subject, greeting, body, case_id, dob_hint, login_by_case_url, login_by_email_url`.
- Use a public logo URL in the template (browser clients canâ€™t attach CID images).

Provide the Service ID and template IDs in the frontend `.env` as shown above. The app will:
- Send doctor credentials right after creation (uses the password entered at creation time)
- Send patient case access after case creation (two login options: Case ID + DOB, or Email + DOB)
- Case â€œResendâ€ uses EmailJS if patient email exists, otherwise falls back to backend
- Doctor â€œResendâ€ is intentionally removed for security (no plaintext password stored)

<br/>

## ğŸ¤ Contributors
- @Akshaya05-code â€” Kadari Akshaya
- @pranavi-code â€” Ginnareddy Pranavi Reddy
- @gouniaksharareddy â€” Gouni Akshara Reddy
- @Tejaswi-g â€” Gillella Tejaswi
- @guntishivani â€” Gunti Shivani

